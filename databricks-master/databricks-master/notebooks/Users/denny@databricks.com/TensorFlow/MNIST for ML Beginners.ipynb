{"cells":[{"cell_type":"markdown","source":["## MNIST for ML Beginners\nThis is the MNIST for ML Beginners using TensorFlow with Databricks and TensorFrames"],"metadata":{}},{"cell_type":"markdown","source":["### Configuration and Setup\n1. Launch a Spark cluster with version >= 1.6\n2. Attach to this cluster the latest version of the TensorFrames Spark package\n3. In a notebook, run the following command\n * *Ubuntu/Linux 64-bit, CPU only, Python 2.7*\n `/databricks/python/bin/pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl`\n * *Ubuntu/Linux 64-bit, GPU enabled, Python 2.7*\n `/databricks/python/bin/pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl`\n4. Detach and reattach the notebook you just ran this command from\n5. Your cluster is now configured. You can run pure tensorflow programs on the driver, or TensorFrames examples on the whole cluster"],"metadata":{}},{"cell_type":"code","source":["%sh\n/databricks/python/bin/pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### MNIST for ML Beginners\nThis set of cells is based on the [MNIST for ML Beginners](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html). \n\nThe purpose of this notebook is to use TensorFrames and Neural Networks to **automate the identification of handwritten digits** from the  [MNIST Database of Handwritten Digits](http://yann.lecun.com/exdb/mnist/) database. The source of these handwritten digits is from the National Institute of Standards and Technology (NIST) Special Database 3 (Census Bureau employees) and Special Database 1 (high-school students).\n\n![](https://www.tensorflow.org/versions/r0.9/images/MNIST.png)"],"metadata":{}},{"cell_type":"markdown","source":["### Import the Dataset\nThe MNIST dataset is comprised of:\n* `mnist.train`: 55,000 data points of training data \n* `mnist.test`: 10,000 points of test data\n* `mnist.validation`: 5,000 points of validation data"],"metadata":{}},{"cell_type":"code","source":["# Import MNIST digit images data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### What is the image?\nWithin this dataset, this 28px x 28px 3D structure has been flattened into an array of size 784. For this tutorial, we're using a simple algorithm - `softmax regression` which does not actually make use of the 3D structure so we do not lose any information by flattening it 2D. The `.images` contains the [x,784] matrix of representing the digits while the `.labels` contain the `One-Hot Vector` representing the actual number.\n\nFor example, `mnist.train.images[25138,:]` is the array of 784 digits for the handwritten digit number `9` as indicated in `mnist.train.labels[25138,:]`."],"metadata":{}},{"cell_type":"code","source":["# One-Hot Vector for xs = 25138 representing the number 9 \n#  The nth-digit will be represented as a vector which is 1 in the nth dimensions. \nmnist.train.labels[25138,:]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# This is the extracted array for xs = 25138 from the training matrix\nmnist.train.images[25138,:]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["But because the output is 5 columns, its really hard to see that is the number **9**.  \n\nIf you were to take this 11,281 x 5 matrix and convert it back to a 28 x 28 matrix and add a color-scale (the higher the number, the darker the value), you will get this matrix:\n\n![](https://dennyglee.files.wordpress.com/2016/06/unflattened-digit-9-small.png)\n\nHere, you can access the [full-size version](https://dennyglee.files.wordpress.com/2016/06/unflattened-digit-9-full.png) of this image."],"metadata":{}},{"cell_type":"markdown","source":["## Digit Prediction\n\nFor those notebook on MNIST digit prediction, we will use the Softmax Regressions model. \nFor more information, please reference the [softmax regression](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html#softmax-regressions) analysis."],"metadata":{}},{"cell_type":"markdown","source":["#### Implementing Softmax Regressions model"],"metadata":{}},{"cell_type":"code","source":["# Import TensorFlow\nimport tensorflow as tf\n\n# Create `x` placeholder\n#   Place any any number of MNIST images, each flattened into a 784-dimensional vector\n#   This is represented  as a 2-D tensor of floating-point numbers, with a shape [None, 784]\nx = tf.placeholder(tf.float32, [None, 784])\n\n# Set the weights (`W`) and biases (`b`) for our model\n#   Use a Variable - a modificable tensor that lives in TensorFlow's graph of interacting operations\n#   We initalize them them with `zeros`\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n# Implement Softmax Regressions model\ny = tf.nn.softmax(tf.matmul(x, W) + b)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["#### Training the model\nUse the `cross-entropy` cost function to define what it means for the model to be good.  For more information, please reference [MNIST for Beginners > Training](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html#training)"],"metadata":{}},{"cell_type":"code","source":["# Create `y_` placeholder Variable to input correct answers\ny_ = tf.placeholder(tf.float32, [None, 10])\n\n# Implement the `cross-entopy` cost function\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n\n# Traing using back-propagation (gradient descent optimizer)\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n# Initialize all variables \ninit = tf.initialize_all_variables()\n\n# Launch the model in a `Session`, and run the operation that initializes the variables\nsess = tf.Session()\nsess.run(init)\n\n# Let's train -- running the training step 1000 times\nfor i in range(1000):\n  batch_xs, batch_ys = mnist.train.next_batch(100)\n  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nprint(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["len(batch_xs)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["len(batch_ys)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["y"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["y(1,1)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["y[0,0]"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["tf.argmax(y,1)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["tf.eval(tf.argmax(y,1))"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["tf.Print(y, [y])"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["tf.Print(tf.argmax(y,1), [tf.argmax(y,1)])"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":29}],"metadata":{"name":"MNIST for ML Beginners","notebookId":1329451374749978},"nbformat":4,"nbformat_minor":0}
